#!/usr/bin/env bash

# fix segmentation fault reported in https://github.com/k2-fsa/icefall/issues/674
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

set -eou pipefail

nj=15
# run step 0 to step 5 by default
stage=0
stop_stage=5


# We assume dl_dir (download dir) contains the following
# directories and files. If not, they will be downloaded
# by this script automatically.
#
#  - $dl_dir/dataoceanai-arabic

dl_dir=$PWD/download

. shared/parse_options.sh || exit 1

# vocab size for sentence piece models.
# It will generate data/lang_bpe_xxx,
# data/lang_bpe_yyy if the array contains xxx, yyy
vocab_sizes=(
  # 5000
  # 2000
  # 1000
  500
)

# All files generated by this script are saved in "data".
# You can safely remove "data" and rerun this script to regenerate it.
mkdir -p data

log() {
  # This function is from espnet
  local fname=${BASH_SOURCE[1]##*/}
  echo -e "$(date '+%Y-%m-%d %H:%M:%S') (${fname}:${BASH_LINENO[0]}:${FUNCNAME[1]}) $*"
}

log "Running prepare.sh"

log "dl_dir: $dl_dir"


if [ $stage -le 0 ] && [ $stop_stage -ge 0 ]; then
  log "Stage 0: Download data"

  # If you have pre-downloaded it to /path/to/dataoceanai-arabic,
  # you can create a symlink
  #
  #   ln -sfv /path/to/dataoceanai-arabic $dl_dir/dataoceanai-arabic
  #
  if [ ! -d $dl_dir/dataoceanai-arabic/audio ]; then
    pip install huggingface_hub
    huggingface-cli login
    huggingface-cli download  --repo-type dataset  --local-dir download/dataoceanai-arabic  yfyeung/dataoceanai-arabic
  fi
fi

if [ $stage -le 1 ] && [ $stop_stage -ge 1 ]; then
  log "Stage 1: Prepare dataoceanai-arabic manifest"
  # We assume that you have downloaded the dataoceanai-arabic corpus
  # to $dl_dir/dataoceanai-arabic
  mkdir -p data/manifests
  if [ ! -e data/manifests/.dataoceanai-arabic.done ]; then
    pip install git+https://github.com/yfyeung/lhotse.git@textgrid
    lhotse prepare textgrids dataoceanai-alg $dl_dir/dataoceanai-arabic/audio $dl_dir/dataoceanai-arabic/textgrid/test data/manifests --language Algeriain -j $nj
    lhotse prepare textgrids dataoceanai-alg $dl_dir/dataoceanai-arabic/audio $dl_dir/dataoceanai-arabic/textgrid/train data/manifests --language Algeriain -j $nj
    touch data/manifests/.dataoceanai-arabic.done
  fi
fi

if [ $stage -le 2 ] && [ $stop_stage -ge 2 ]; then
  log "Stage 2: Preprocess dataoceanai-arabic manifest"
  if [ ! -e data/fbank/.preprocess_dataoceanai-arabic.done ]; then
    ./local/preprocess_dataoceanai_arabic.py
    touch data/fbank/.preprocess_dataoceanai-arabic.done
  fi
fi

if [ $stage -le 3 ] && [ $stop_stage -ge 3 ]; then
  log "Stage 3: Compute fbank for dataoceanai-arabic"
  mkdir -p data/fbank
  if [ ! -e data/fbank/.dataoceanai-arabic.done ]; then
    ./local/compute_fbank_dataoceanai_arabic.py
    touch data/fbank/.dataoceanai-arabic.done
  fi
fi

if [ $stage -le 4 ] && [ $stop_stage -ge 4 ]; then
  log "Stage 4: Prepare BPE based lang"

  for vocab_size in ${vocab_sizes[@]}; do
    lang_dir=data/lang_bpe_${vocab_size}
    mkdir -p $lang_dir

    if [ ! -f $lang_dir/transcript_words.txt ]; then
      log "Generate data for BPE training"
      files=$(
        find "$dl_dir/dataoceanai-arabic/train-clean-100" -name "*.trans.txt"
        find "$dl_dir/dataoceanai-arabic/train-clean-360" -name "*.trans.txt"
        find "$dl_dir/dataoceanai-arabic/train-other-500" -name "*.trans.txt"
      )
      for f in ${files[@]}; do
        cat $f | cut -d " " -f 2-
      done > $lang_dir/transcript_words.txt
    fi

    if [ ! -f $lang_dir/bpe.model ]; then
      ./local/train_bpe_model.py \
        --lang-dir $lang_dir \
        --vocab-size $vocab_size \
        --transcript $lang_dir/transcript_words.txt
    fi
  done
fi
